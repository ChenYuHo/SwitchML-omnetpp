[General]
network = TwoLayers
simtime-resolution = ps
cmdenv-status-frequency = 60s
**.switch_ports = 16
**.max_jobs_to_submit = 2
**.file = "60_job.csv"
**.num_slots = 512
**.MTU = 9000
**.num_gpus = 8
**.collective_scheduler.typename = "None"
**.datarate = 100Gbps
**.delay = 1us
**.job_placement = "random_multiracks"
**.gpu_type = "a100"
#seed-set = 2
#repeat = 20
#sim-time-limit = 1ps
#**.tor_worker_channel**.result-recording-modes = all,+vector,+histogram
#**.job_dispatcher.**.result-recording-modes = -
#**.workers[*].**.result-recording-modes = -
#include partition.ini

[Models]
result-dir = models2/
seed-set = 138
**.switch_ports = 11
**.num_gpus = 1
**.max_jobs_to_submit = 10
**.file = "models.csv"
**.job_placement = "random_singlerack"
**.tor_worker_channel**.result-recording-modes = all,+vector,+histogram

[AllConfigs]
**.collective_scheduler.typename = ${CollectiveScheduler="None", "FifoExclusive", "ByteScheduler", "SincroniaExclusive", "Sincronia", "DeficitRoundRobinExclusive", "DeficitRoundRobin"}

[TwoJob]
**.switch_ports = 3
**.file = "two_jobs.csv"
**.job_placement = "two_jobs"
**.tor_core_channel.typename = "Ideal"
**.delay = 1us

[Exp60Jobs]
extends = AllConfigs
result-dir = tensorkey2/
**.job_placement = ${JobPlacement="random_singlerack", "random_multiracks", "random_distributed", "random"}
**.submit_all_when_start = ${SubmitAllAtStart=true, false}
**.switch_ports = 10
**.num_gpus = 4
**.gpu_scale_factor = 2
**.max_jobs_to_submit = 99
**job_dispatcher**.cmdenv-log-level = debug
**.cmdenv-log-level = off


[TestCollectiveScheduler]
**.num_slots = 5
**.num_updates = 1000
**.num_gpus = 4
**.MTU = 1500
**.file = "1.csv"
**.switch_ports = 3
**.max_jobs_to_submit = 5

[TestFifoExclusive]
extends = TestCollectiveScheduler
**.collective_scheduler.typename = "FifoExclusive"

[TestByteScheduler]
# should see:
# layer 2 chunk 1
# layer 0 chunk 1
# layer 0 chunk 2
# layer 1 chunk 1
# layer 1 chunk 2
# layer 2 chunk 2
extends = TestCollectiveScheduler
**.custom_model = true
# **.custom_model_sizes = "100000,10000,1000000"
# **.custom_fp_times = "2,300000,4"
# **.custom_bp_times = "70000,8,9"
# **.custom_wu_times = "3,7,9000000"
**.custom_model_sizes = "100,100,100"
**.custom_fp_times = "2,3,4"
**.custom_bp_times = "7,8,9"
**.custom_wu_times = "3,7,9"
**.custom_iters = 3
**.collective_scheduler.typename = "ByteScheduler"
**.chunk_size = 90
**.max_jobs_to_submit = 1
**.collective_scheduler.cmdenv-log-level = debug
**Rank0**.cmdenv-log-level = debug
**.cmdenv-log-level = off

[TestByteScheduler_NoSimPkt]
extends = TestByteScheduler
**.packet_simulation = false
**.worker**.cmdenv-log-level = debug


[TestSincronia]
extends = TestCollectiveScheduler
#**.custom_model = true
#**.custom_model_sizes = "2621440,1321440,4321440"
#**.custom_iters = 3
**.switch_ports = 4
**.num_gpus = 4
**.gpu_scale_factor = 2
**.submit_all_when_start = true
**.collective_scheduler.typename = "Sincronia"
#**.chunk_size = 2621440
**.file = "60_job.csv"
**.max_jobs_to_submit = 5
**.collective_scheduler.cmdenv-log-level = debug
**.job_dispatcher.cmdenv-log-level = debug
#**Rank0**.cmdenv-log-level = debug
#**.cmdenv-log-level = off


[TestDRR]
extends = TestCollectiveScheduler
#**.custom_model = true
#**.custom_model_sizes = "2621440,1321440,4321440"
#**.custom_iters = 3
**.switch_ports = 4
**.num_gpus = 4
**.gpu_scale_factor = 2
**.submit_all_when_start = true
**.collective_scheduler.typename = "DeficitRoundRobin"
#**.chunk_size = 2621440
**.file = "60_job.csv"
**.max_jobs_to_submit = 5
**.collective_scheduler.cmdenv-log-level = debug
**.job_dispatcher.cmdenv-log-level = debug
**Rank0**.cmdenv-log-level = debug
**.cmdenv-log-level = off

[TestMultiRackFallback]
**.job_placement = "random_multiracks_fallback"


[TestEvLog]
**.num_slots = 2
**.num_updates = 10
**.num_gpus = 4
**.MTU = 1500
**.file = "1.csv"
**.switch_ports = 2

[Single]
result-dir = single/
**.job_submitter.typename = "NJobSubmitter"
**.delay = 0s
**.switch_ports = 3
**.num_jobs = 1
**.custom_model = true
**.custom_model_sizes = "2,2,2"
**.custom_fp_times = "1000000000000,1000000000000,1000000000000" # 1s
**.custom_bp_times = "1000000000000,1000000000000,1000000000000"
**.custom_wu_times = "1000000000000,1000000000000,1000000000000"
**.custom_iters = 1
**.num_slots = 1
**.MTU = 25000000000
**.chunk_size = 1
**.num_updates = 1
**.collective_scheduler.typename = ${CollectiveScheduler="None", "FifoExclusive", "ByteScheduler", "Sincronia", "DeficitRoundRobin"}

[Exp15Jobs]
extends = AllConfigs
result-dir = 15_jobs/
cmdenv-status-frequency = 60s
**.job_submitter.typename = "NJobSubmitter"
**.num_jobs = 15
**.iters = 3
**.num_gpus_per_job = 4
**.model = ${model="alexnet", "vgg19", "resnet50", "bert"}
**.switch_ports = 4
**.num_gpus = 5
**.job_placement = ${JobPlacement="random_singlerack_fallback", "random_multiracks_fallback"}
**.cmdenv-log-level = off

[Two]
result-dir = two_workers/
**.file = "two_workers.csv"
#**.job_submitter.typename = "NJobSubmitter"
**.delay = 0s
**.switch_ports = 2
#**.num_jobs = 8
#**.num_gpus_per_job = 2
**.num_gpus = 8
#**.custom_model = true
#**.custom_model_sizes = "2,2,2"
#**.custom_fp_times = "1000000000000,1000000000000,1000000000000" # 1s
#**.custom_bp_times = "1000000000000,1000000000000,1000000000000"
#**.custom_wu_times = "1000000000000,1000000000000,1000000000000"
#**.custom_iters = 1
**.print_only_rank0 = true
#**.num_slots = 1
#**.MTU = 25000000000
#**.chunk_size = 1
#**.num_updates = 1
**.job_placement = "random_multiracks"
**.iters = 3
#**.model = ${model="alexnet", "vgg19", "resnet50", "bert"}
**.collective_scheduler.typename = ${CollectiveScheduler="None", "FifoExclusive", "ByteScheduler", "Sincronia", "SincroniaExclusive", "DeficitRoundRobin"}

[Bandwidth_vs_Throughput]
result-dir = bw_tput/
**.delay = 1us

**.MTU = 9000
**.datarate = ${bw=10..100 step 10}Gbps
**.num_slots = ${slots=1,2,4,8,16,32,64,128,256,512}
# only 100Gbps varies num_slots, others bandwidths fixed at num_slots=512
constraint = (($bw < 100) && ($slots == 512)) || (($bw == 100) && ($slots > 0))
**.gpu_type = ${GPU="a100", "v100", "a100_match_v100_bs"}
**.switch_ports = 3
**.num_gpus = 2
**.job_placement = ${JobPlacement="custom"}
**.custom_placement = "1-0&1"
# example: 5-0&2,4-1:4&3:2,7-3
# comma separates placement_str as job_placement, whose format is JID-PLACEMENT
# & separates PLACEMENT as worker_gpus, whose format is WID:NUM_GPUS where NUM_GPUS defaults to 1 if no ":" exists

#**.result-recording-modes = -
#**.retransmission_timeout = 10ms
**.job_submitter.typename = "NJobSubmitter"
**.num_jobs = 1
**.iters = 10
**.num_gpus_per_job = 2
**.model = ${model="alexnet", "vgg11", "vgg16", "vgg19", "resnet50", "resnet101", "resnet152", "inception", "googlenet", "bert"}
#**.tor_worker_channel**.result-recording-modes = all,+vector,+histogram
**.workers[0]**.tor_worker_channel**.result-recording-modes = all,+vector,+histogram
**.workers[1]**.tor_worker_channel**.result-recording-modes = all,+vector,+histogram
**.tors[0]**.tor_worker_channel**.result-recording-modes = all,+vector,+histogram
#**.tors[1].down_ports$o[1].tor_worker_channel.result-recording-modes = all,+vector,+histogram


[Exp300Jobs]
extends = AllConfigs
result-dir = 300_jobs/
cmdenv-status-frequency = 60s
**.job_submitter.typename = "NJobSubmitter"
**.num_jobs = 300
**.iters = 5
**.num_gpus_per_job = 8
**.model = ${model="alexnet", "vgg11", "vgg16", "vgg19", "resnet50", "resnet101", "resnet152", "inception", "googlenet", "bert"}
**.switch_ports = 16
**.num_gpus = 10
**.job_placement = ${JobPlacement="random_singlerack_fallback", "random_multiracks_fallback", "random_distributed_fallback", "random"}
**.cmdenv-log-level = off

[TestCongestion]
**.delay = 1us
seed-set = 2
**.MTU = 9000
#**.num_updates = ${nu=64, 256}
**.datarate = 100Gbps
**.num_slots = 512
**.switch_ports = 3
**.num_gpus = 16
**.file = "96.csv"
**.max_jobs_to_submit = 48
**.job_placement = ${JobPlacement="random_singlerack", "random_multiracks"}
**.custom_model = true
**.custom_model_sizes = "26214400"
**.custom_iters = 1
#**.result-recording-modes = -
**.retransmission_timeout = 10ms

[TestCongestionCollectiveScheduler]
**.delay = 1us
seed-set = 2
**.MTU = 9000
#**.num_updates = ${nu=64, 256}
**.datarate = 100Gbps
**.num_slots = 512
**.switch_ports = 3
**.num_gpus = 16
**.file = "96.csv"
**.max_jobs_to_submit = 48
**.custom_model = true
**.custom_model_sizes = "26214400"
**.custom_iters = 1
#**.result-recording-modes = -
**.retransmission_timeout = 10ms
**.collective_scheduler.typename = ${CollectiveScheduler="None", "FifoExclusive", "ByteScheduler", "SincroniaExclusive", "Sincronia", "DeficitRoundRobinExclusive", "DeficitRoundRobin"}
**.job_placement = ${JobPlacement="random_singlerack", "random_multiracks", "random_singlerack_fallback", "random_multiracks_fallback", "random_distributed_fallback", "random"}

[TestCongestionSmall]
**.delay = 1us
seed-set = 2
#repeat = 20
#sim-time-limit = 1ps
**.MTU = 9000
**.datarate = 100Gbps
**.num_slots = 512
**.switch_ports = 3
**.num_gpus = 8
**.file = "96.csv"
**.max_jobs_to_submit = 24
**.job_placement = ${JobPlacement="random_singlerack", "random_multiracks"}
**.custom_model = true
**.custom_model_sizes = "26214400"
**.custom_iters = 1
#**.result-recording-modes = -
**.retransmission_timeout = 10ms

[Bert300]
extends = AllConfigs
result-dir = bert_300/
cmdenv-status-frequency = 60s
**.job_placement = ${JobPlacement="random_singlerack_fallback", "random_multiracks_fallback", "random_distributed_fallback", "random"}
**.switch_ports = 16
**.submit_all_when_start = true
**.num_gpus = 10
**.file = "300_bert.csv"
**.max_jobs_to_submit = 9999
**.job_dispatcher**.cmdenv-log-level = debug
**.cmdenv-log-level = off

[SwitchMLPaper]
**.tor_core_channel.typename = "Ideal"
**.delay = 1us
**.MTU = 0
**.num_updates = ${nu=64, 256}
**.datarate = ${bw=10, 100}Gbps
**.num_slots = ${ns=128, 512 ! bw}
**.switch_ports = 3
**.num_gpus = 2
**.file = "1.csv"
**.max_jobs_to_submit = 1
**.job_placement = ${JobPlacement="custom"}
**.custom_placement = "0-0&1"
**.custom_model = true
**.custom_model_sizes = "26214400"
**.custom_iters = 1
**.retransmission_timeout = 10ms

[SwitchMLPaper_NoSimPkt]
extends = SwitchMLPaper
**.packet_simulation = false
**.collective_scheduler.cmdenv-log-level = debug
**Rank0**.cmdenv-log-level = debug
**.worker**.cmdenv-log-level = debug
**.job_dispatcher**.cmdenv-log-level = debug
**.cmdenv-log-level = off


[TestSincroniaSmall]
result-dir = small2/
**.gpu_type = "a100_match_v100_bs"
**.MTU = 1500
**.switch_ports = 3
**.num_gpus = 8
**.file = "small.csv"
**.max_jobs_to_submit = 8
**.job_placement = ${JobPlacement="custom"}
**.custom_placement = "0-0&2,1-0&2,2-0&2,3-0&2,4-0&2,5-0&2,6-0&2,7-0&2"
#**.custom_placement = "0-0&2,1-1&3,2-2&4,3-3&5,4-0&4,5-1&5"
**.submit_all_when_start = true
**.collective_scheduler.typename = ${CollectiveScheduler="None", "ByteScheduler", "Sincronia", "DeficitRoundRobin"}
#**.chunk_size = 2621440
**.collective_scheduler.cmdenv-log-level = debug
#**.job_dispatcher.cmdenv-log-level = debug
#**Rank0**.cmdenv-log-level = debug
**.cmdenv-log-level = off
**.workers[0]**.tor_worker_channel**.result-recording-modes = all,-vector,-histogram
**.workers[2]**.tor_worker_channel**.result-recording-modes = all,-vector,-histogram

